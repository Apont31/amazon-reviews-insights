{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0021b77e",
   "metadata": {},
   "source": [
    "\n",
    "# üß™ C5.2.2 ‚Äî S√©lection de variables (Bloc 5)\n",
    "\n",
    "**Objectif :** choisir et justifier des **m√©thodes de s√©lection de variables** pour r√©duire la dimension, am√©liorer la\n",
    "g√©n√©ralisation et l'explicabilit√©. On compare **plusieurs familles** :  \n",
    "- **Filtre (statistique)** : test **chi¬≤** sur TF‚ÄëIDF (non‚Äën√©gatif)  \n",
    "- **M√©thode incorpor√©e (embedded)** : **L1** (LASSO) via `LogisticRegression` + `SelectFromModel`  \n",
    "- **R√©duction de dimension** : **TruncatedSVD** (LSA) sur matrices creuses  \n",
    "*(option)* **RFE** sur un sous‚Äëensemble pour illustrer l'√©limination r√©cursive\n",
    "\n",
    "On s'appuie sur les features g√©n√©r√©s en **C5.2.1**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7cca54",
   "metadata": {},
   "source": [
    "\n",
    "## üéôÔ∏è Discours (1‚Äì2 min)\n",
    "> ¬´ Nous retenons un triptyque compl√©mentaire : **chi¬≤** (rapide, interpretable), **L1** (s√©lection parcimonieuse embarqu√©e),\n",
    "> et **SVD** (compression th√©matique). Nous comparons l'impact sur AP/F1 et le **nombre de variables** conserv√©es,\n",
    "> puis nous **s√©rialisons** les s√©lecteurs pour l'entra√Ænement (C5.2.3). ¬ª\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c2d6c8",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 0) Configuration & chemins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cfb1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Artefacts de C5.2.1\n",
    "X_PATH = Path(\"data/processed/X_tfidf_sample.npz\")\n",
    "Y_PATH = Path(\"data/processed/y_binary_sample.joblib\")\n",
    "FEAT_ART = Path(\"models\")  # on prendra le plus r√©cent features_tfidf_*.joblib\n",
    "\n",
    "# Param√®tres s√©lection\n",
    "CHI2_K = 50_000            # k pour SelectKBest(chi2)\n",
    "L1_C   = 0.5               # r√©gularisation L1 (plus petit => plus de shrinkage)\n",
    "SVD_K  = 300               # nb composantes SVD\n",
    "\n",
    "DO_RFE = False             # RFE tr√®s co√ªteux en tr√®s haute dimension (False par d√©faut)\n",
    "RFE_N_FEATURES = 5_000     # si DO_RFE=True, cible finale (apr√®s pr√©filtre)\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7669599b",
   "metadata": {},
   "source": [
    "## üì• 1) Chargement X/y + artefacts de noms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c964a1d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "\n",
    "import json, re, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "from scipy import sparse\n",
    "\n",
    "assert X_PATH.exists() and Y_PATH.exists(), \"Ex√©cute d'abord C5.2.1 pour produire X/y.\"\n",
    "X = sparse.load_npz(X_PATH)\n",
    "y = load(Y_PATH)\n",
    "\n",
    "# R√©cup√©rer le plus r√©cent artefact features_tfidf_*.joblib\n",
    "feat_jobs = sorted(FEAT_ART.glob(\"features_tfidf_*.joblib\"))\n",
    "assert feat_jobs, \"Artefact features_tfidf_*.joblib introuvable (C5.2.1).\"\n",
    "feat_job = feat_jobs[-1]\n",
    "art = load(feat_job)\n",
    "\n",
    "# Construire la liste des noms de features (mot + char + meta)\n",
    "names = []\n",
    "if art.get(\"vectorizer_word\") is not None:\n",
    "    names += list(art[\"vectorizer_word\"].get_feature_names_out())\n",
    "if art.get(\"vectorizer_char\") is not None:\n",
    "    names += list(art[\"vectorizer_char\"].get_feature_names_out())\n",
    "if art.get(\"feature_meta_cols\"):\n",
    "    names += list(art[\"feature_meta_cols\"])\n",
    "feature_names = np.array(names, dtype=object)\n",
    "print(\"X shape:\", X.shape, \"| y:\", y.shape, \"| nb_features:\", len(feature_names), \"| artefact:\", feat_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140bb1b7",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è 2) Split train/test (stratifi√©, reproductible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a96b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96000, 180007), (24000, 180007), 0.7614583333333333, 0.7614583333333333)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "Xtr.shape, Xte.shape, ytr.mean(), yte.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968cab8c",
   "metadata": {},
   "source": [
    "## üß∞ 3) Utilitaire d'√©valuation rapide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e5bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, f1_score, precision_recall_curve\n",
    "\n",
    "def eval_pipeline(Xtr, Xte, ytr, yte, desc: str):\n",
    "    t0 = time.time()\n",
    "    clf = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "    clf.fit(Xtr, ytr)\n",
    "    fit_s = time.time() - t0\n",
    "    proba = clf.predict_proba(Xte)[:,1]\n",
    "    ap = average_precision_score(yte, proba)\n",
    "    # F1@0.5 et F1 optimal\n",
    "    prec, rec, thr = precision_recall_curve(yte, proba)\n",
    "    f1 = (2*prec*rec)/(prec+rec+1e-9)\n",
    "    best_idx = int(np.nanargmax(f1))\n",
    "    thr_star = float(thr[best_idx]) if best_idx < len(thr) else 0.5\n",
    "    f1_star = float(f1[best_idx])\n",
    "    f1_05 = f1_score(yte, proba>=0.5)\n",
    "    print(f\"[{desc}] AP={ap:.3f} | F1@0.5={f1_05:.3f} | F1@t*={f1_star:.3f} (t*={thr_star:.2f}) | fit={fit_s:.2f}s\")\n",
    "    return {\"desc\": desc, \"AP\": ap, \"F1@0.5\": f1_05, \"F1@t*\": f1_star, \"t*\": thr_star, \"fit_s\": fit_s}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9ffed",
   "metadata": {},
   "source": [
    "## üéöÔ∏è 4) Baseline sans s√©lection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "574e533f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline (no selection) ‚Äî p=180,007] AP=0.983 | F1@0.5=0.927 | F1@t*=0.938 (t*=0.31) | fit=342.86s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antoi\\anaconda3\\envs\\monenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "desc",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1@0.5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1@t*",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t*",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fit_s",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ad8c2002-9000-4462-9edc-e6bd99af8a36",
       "rows": [
        [
         "0",
         "Baseline (no selection) ‚Äî p=180,007",
         "0.9826588467886541",
         "0.9272835347731325",
         "0.9375033931037654",
         "0.30982714229856223",
         "342.8643469810486"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>AP</th>\n",
       "      <th>F1@0.5</th>\n",
       "      <th>F1@t*</th>\n",
       "      <th>t*</th>\n",
       "      <th>fit_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (no selection) ‚Äî p=180,007</td>\n",
       "      <td>0.982659</td>\n",
       "      <td>0.927284</td>\n",
       "      <td>0.937503</td>\n",
       "      <td>0.309827</td>\n",
       "      <td>342.864347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  desc        AP    F1@0.5     F1@t*  \\\n",
       "0  Baseline (no selection) ‚Äî p=180,007  0.982659  0.927284  0.937503   \n",
       "\n",
       "         t*       fit_s  \n",
       "0  0.309827  342.864347  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "res = []\n",
    "res.append(eval_pipeline(Xtr, Xte, ytr, yte, desc=f\"Baseline (no selection) ‚Äî p={Xtr.shape[1]:,}\"))\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c1c6f9",
   "metadata": {},
   "source": [
    "### üîç Sauvegarde des artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b25c3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√âcrit ‚Üí models\\selector_chi2_k50000_20250912_171611.joblib\n",
      "√âcrit ‚Üí models/selection_decision_20250912_171611.json\n"
     ]
    }
   ],
   "source": [
    "# üíΩ Sauvegarde du s√©lecteur chi¬≤ choisi + m√©ta d√©cision pour C5.2.3\n",
    "from joblib import dump\n",
    "from pathlib import Path\n",
    "import time, json\n",
    "\n",
    "# `sel` = votre SelectKBest(chi2, k=50_000) fit dans la cellule de comparaison\n",
    "assert 'sel' in globals(), \"Le s√©lecteur `sel` doit √™tre cr√©√© plus haut.\"\n",
    "\n",
    "Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
    "stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# 1) s√©lecteur chi¬≤\n",
    "sel_path = Path(\"models\")/f\"selector_chi2_k{sel.k}_{stamp}.joblib\"\n",
    "dump({\"chi2\": sel, \"k\": int(sel.k)}, sel_path)\n",
    "\n",
    "# 2) m√©ta d√©cision (pour tracer le choix dans le repo)\n",
    "decision = {\n",
    "    \"chosen_pipeline\": \"tfidf -> chi2(k=50k) -> logreg(lbfgs, L2, C=1.0)\",\n",
    "    \"k\": int(sel.k),\n",
    "    \"logreg\": {\"solver\": \"lbfgs\", \"penalty\": \"l2\", \"C\": 1.0, \"max_iter\": 5000, \"tol\": 1e-3},\n",
    "    \"notes\": \"Qualit√© ‚âà baseline; fit ~2.5x plus rapide; calibration pr√©serv√©e (t*‚âà0.31).\",\n",
    "    \"created\": stamp\n",
    "}\n",
    "(Path(\"models\")/f\"selection_decision_{stamp}.json\").write_text(json.dumps(decision, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"√âcrit ‚Üí\", sel_path)\n",
    "print(\"√âcrit ‚Üí\", f\"models/selection_decision_{stamp}.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1223d83c",
   "metadata": {},
   "source": [
    "# üìà 5) Filtre chi¬≤ ‚Äî SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06673871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi¬≤ s√©lectionne k=50,000 features  |  Xtr_chi: (96000, 50000)  |  Xte_chi: (24000, 50000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# k d√©fini dans ta cellule de config (ex. CHI2_K=50_000)\n",
    "k = min(CHI2_K, Xtr.shape[1])\n",
    "\n",
    "# S√©lecteur chi¬≤\n",
    "sel = SelectKBest(score_func=chi2, k=k).fit(Xtr, ytr)\n",
    "Xtr_chi = sel.transform(Xtr)\n",
    "Xte_chi = sel.transform(Xte)\n",
    "\n",
    "print(f\"chi¬≤ s√©lectionne k={k:,} features  |  Xtr_chi: {Xtr_chi.shape}  |  Xte_chi: {Xte_chi.shape}\")\n",
    "\n",
    "# (pour la cellule 5bis)\n",
    "mask = sel.get_support()\n",
    "selected_names = feature_names[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ffcb5",
   "metadata": {},
   "source": [
    "### üîç 5bis) Top features (chi¬≤) ‚Äî termes les plus discriminants\n",
    "> Interpr√©tation : plus le **score œá¬≤** est √©lev√©, plus la variable discrimine les classes (0/1). On documente les 25 premiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1035a",
   "metadata": {},
   "source": [
    "### üîç Top features (chi¬≤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e6af0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "chi2_score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a70dbc76-3b28-407e-89df-ef9ebc1b6656",
       "rows": [
        [
         "0",
         "review_len",
         "623855.8120997995"
        ],
        [
         "1",
         "word_count",
         "115366.20071073562"
        ],
        [
         "2",
         "helpful_vote",
         "23897.49048195922"
        ],
        [
         "3",
         "ques_count",
         "1335.4420569516656"
        ],
        [
         "4",
         "bang_count",
         "722.8202676641952"
        ],
        [
         "5",
         "great",
         "580.9754335256779"
        ],
        [
         "6",
         "return",
         "502.6516287739924"
        ],
        [
         "7",
         "stopped",
         "487.0383685121561"
        ],
        [
         "8",
         "waste",
         "434.4919781124562"
        ],
        [
         "9",
         "stopped working",
         "421.23018742318965"
        ],
        [
         "10",
         "love",
         "385.10616252805255"
        ],
        [
         "11",
         "waste money",
         "374.8108858228327"
        ],
        [
         "12",
         "returned",
         "354.12445366158414"
        ],
        [
         "13",
         "broke",
         "326.79449713503305"
        ],
        [
         "14",
         "did work",
         "319.0730578356417"
        ],
        [
         "15",
         "months",
         "315.49212027200133"
        ],
        [
         "16",
         "works",
         "306.72283029399944"
        ],
        [
         "17",
         "not ",
         "305.4960006938597"
        ],
        [
         "18",
         "work",
         "289.5976559592865"
        ],
        [
         "19",
         "doesn work",
         "282.31699881282054"
        ],
        [
         "20",
         "not",
         "274.30933196909234"
        ],
        [
         "21",
         " not ",
         "272.8450970249077"
        ],
        [
         "22",
         "didn work",
         "272.5603474468528"
        ],
        [
         "23",
         " not",
         "262.36590787625966"
        ],
        [
         "24",
         "retu",
         "253.53618101039876"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 25
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>chi2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>review_len</td>\n",
       "      <td>623855.812100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word_count</td>\n",
       "      <td>115366.200711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>helpful_vote</td>\n",
       "      <td>23897.490482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ques_count</td>\n",
       "      <td>1335.442057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bang_count</td>\n",
       "      <td>722.820268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>great</td>\n",
       "      <td>580.975434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>return</td>\n",
       "      <td>502.651629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stopped</td>\n",
       "      <td>487.038369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>waste</td>\n",
       "      <td>434.491978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stopped working</td>\n",
       "      <td>421.230187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>love</td>\n",
       "      <td>385.106163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>waste money</td>\n",
       "      <td>374.810886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>returned</td>\n",
       "      <td>354.124454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>broke</td>\n",
       "      <td>326.794497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>did work</td>\n",
       "      <td>319.073058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>months</td>\n",
       "      <td>315.492120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>works</td>\n",
       "      <td>306.722830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>not</td>\n",
       "      <td>305.496001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>work</td>\n",
       "      <td>289.597656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>doesn work</td>\n",
       "      <td>282.316999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>not</td>\n",
       "      <td>274.309332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>not</td>\n",
       "      <td>272.845097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>didn work</td>\n",
       "      <td>272.560347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>not</td>\n",
       "      <td>262.365908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>retu</td>\n",
       "      <td>253.536181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature     chi2_score\n",
       "0        review_len  623855.812100\n",
       "1        word_count  115366.200711\n",
       "2      helpful_vote   23897.490482\n",
       "3        ques_count    1335.442057\n",
       "4        bang_count     722.820268\n",
       "5             great     580.975434\n",
       "6            return     502.651629\n",
       "7           stopped     487.038369\n",
       "8             waste     434.491978\n",
       "9   stopped working     421.230187\n",
       "10             love     385.106163\n",
       "11      waste money     374.810886\n",
       "12         returned     354.124454\n",
       "13            broke     326.794497\n",
       "14         did work     319.073058\n",
       "15           months     315.492120\n",
       "16            works     306.722830\n",
       "17             not      305.496001\n",
       "18             work     289.597656\n",
       "19       doesn work     282.316999\n",
       "20              not     274.309332\n",
       "21             not      272.845097\n",
       "22        didn work     272.560347\n",
       "23              not     262.365908\n",
       "24             retu     253.536181"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Top features (chi¬≤) √† partir du s√©lecteur `sel` ---\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "scores_all = sel.scores_              # scores par feature (dans l'espace original)\n",
    "mask = sel.get_support()              # bool√©en: features retenues\n",
    "selected_names = feature_names[mask]  # noms des features retenues\n",
    "\n",
    "# Nettoyage NaN/inf et tri d√©croissant\n",
    "scores_sel = np.nan_to_num(scores_all[mask], nan=0.0, posinf=0.0, neginf=0.0)\n",
    "order = np.argsort(scores_sel)[::-1]            # d√©croissant\n",
    "top_n = 25\n",
    "top_df = pd.DataFrame({\n",
    "    \"feature\": selected_names[order][:top_n],\n",
    "    \"chi2_score\": scores_sel[order][:top_n].astype(float)\n",
    "})\n",
    "top_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f57c24",
   "metadata": {},
   "source": [
    "## üß≤ 6) M√©thode incorpor√©e ‚Äî L1 (LogReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1cc6d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi¬≤(k=50,000) ‚Üí L1(thr=median) ‚Üí kept = 25,000 / 50,000\n",
      "[chi¬≤(k=50,000) ‚Üí L1(thr=median) ‚Üí lbfgs] AP=0.982 | F1@0.5=0.921 | F1@t*=0.936 (t*=0.27) | fit=157.48s\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "desc",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1@0.5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1@t*",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t*",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fit_s",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b748794a-c400-4c34-8f92-1925fe3c08f1",
       "rows": [
        [
         "0",
         "chi¬≤(k=50,000) ‚Üí L1(thr=median) ‚Üí lbfgs",
         "0.9817723811867631",
         "0.921263877028181",
         "0.935694514857695",
         "0.26747602855195807",
         "157.47732949256897"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>AP</th>\n",
       "      <th>F1@0.5</th>\n",
       "      <th>F1@t*</th>\n",
       "      <th>t*</th>\n",
       "      <th>fit_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chi¬≤(k=50,000) ‚Üí L1(thr=median) ‚Üí lbfgs</td>\n",
       "      <td>0.981772</td>\n",
       "      <td>0.921264</td>\n",
       "      <td>0.935695</td>\n",
       "      <td>0.267476</td>\n",
       "      <td>157.477329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      desc        AP    F1@0.5     F1@t*  \\\n",
       "0  chi¬≤(k=50,000) ‚Üí L1(thr=median) ‚Üí lbfgs  0.981772  0.921264  0.935695   \n",
       "\n",
       "         t*       fit_s  \n",
       "0  0.267476  157.477329  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## üß≤ 6bis) M√©thode incorpor√©e ‚Äî L1 sur l‚Äôespace chi¬≤(k) + √©valuation lbfgs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# 0) S√©lection L1 (parcimonie) sur l‚Äôespace d√©j√† filtr√© par chi¬≤\n",
    "l1_clf = LogisticRegression(\n",
    "    penalty=\"l1\", solver=\"saga\", C=1.0,             # tu peux tester 0.5 / 1.0\n",
    "    class_weight=\"balanced\", max_iter=3000, tol=1e-3\n",
    ")\n",
    "sfm = SelectFromModel(l1_clf, threshold=\"median\", prefit=False)   # ~50% des + fortes\n",
    "Xtr_l1 = sfm.fit_transform(Xtr_chi, ytr)\n",
    "Xte_l1 = sfm.transform(Xte_chi)\n",
    "print(f\"chi¬≤(k={sel.k:,}) ‚Üí L1(thr=median) ‚Üí kept = {Xtr_l1.shape[1]:,} / {Xtr_chi.shape[1]:,}\")\n",
    "\n",
    "# 1) √âvaluation du pipeline final sur ces variables (lbfgs reste meilleur chez toi)\n",
    "res_l1 = eval_pipeline(\n",
    "    Xtr_l1, Xte_l1, ytr, yte,\n",
    "    desc=f\"chi¬≤(k={sel.k:,}) ‚Üí L1(thr=median) ‚Üí lbfgs\"\n",
    ")\n",
    "pd.DataFrame([res_l1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14282c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'desc': 'chi¬≤(k=50,000) ‚Üí L1(thr=median) ‚Üí lbfgs',\n",
       " 'AP': 0.9817723811867631,\n",
       " 'F1@0.5': 0.921263877028181,\n",
       " 'F1@t*': 0.935694514857695,\n",
       " 't*': 0.26747602855195807,\n",
       " 'fit_s': 157.47732949256897}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b923e0d",
   "metadata": {},
   "source": [
    "Lecture express (√† coller sous la cellule ‚Äì Markdown pr√™t)\n",
    "\n",
    "chi¬≤(50k) ‚Üí L1(thr=median) ‚Üí lbfgs\n",
    "\n",
    "La m√©thode incorpor√©e (L1) a s√©lectionn√© automatiquement ~25k variables parmi les 50k du pr√©-filtre chi¬≤.\n",
    "\n",
    "On obtient un fit 2,4√ó plus rapide qu‚Äôavec chi¬≤+lbfgs pour une perte tr√®s faible : ŒîAP ‚âà ‚Äì0,002, ŒîF1@0.5 ‚âà ‚Äì0,007.\n",
    "\n",
    "Le seuil optimal passe de ~0,31 √† ~0,27, signe d‚Äôune calibration encore correcte.\n",
    "\n",
    "üëâ Cette √©tape coche la case ‚Äúm√©thode incorpor√©e‚Äù (s√©lection pendant l‚Äôapprentissage) et fournit un pipeline light (25k features) utile si l‚Äôon vise moins de RAM/latence.\n",
    "\n",
    "D√©cision pratique :\n",
    "\n",
    "Qualit√© maximale & simplicit√© ‚Üí garder TF-IDF ‚Üí chi¬≤(50k) ‚Üí LogReg L2 (lbfgs).\n",
    "\n",
    "Contraintes de temps/m√©moire ‚Üí envisager TF-IDF ‚Üí chi¬≤(50k) ‚Üí L1 ‚Üí LogReg L2, qui divise par ~2 le nombre de features sans d√©grader significativement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d926325",
   "metadata": {},
   "source": [
    "## üß™ 7) √âvaluation optimis√©e ‚Äî solver & variantes (lbfgs, saga, chi¬≤, SVD)\n",
    "> Objectif : comparer l‚Äôeffet **du solver** et de la **r√©duction de dimension** sur AP, F1, seuil optimal *(t\\*)* et temps d‚Äôentra√Ænement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "368b1aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline lbfgs ‚Äî p=180,007] AP=0.983 | F1@0.5=0.927 | F1@t*=0.938 (t*=0.31) | fit=354.25s\n",
      "[saga C=0.5 tol=1e-3 ‚Äî p=180,007] AP=0.848 | F1@0.5=0.462 | F1@t*=0.865 (t*=0.04) | fit=453.03s\n",
      "[chi2(k=50,000) + saga C=0.5] AP=0.848 | F1@0.5=0.462 | F1@t*=0.865 (t*=0.04) | fit=236.76s\n",
      "[saga C=0.25 tol=1e-3] AP=0.848 | F1@0.5=0.462 | F1@t*=0.865 (t*=0.04) | fit=523.04s\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "desc",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1@0.5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1@t*",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "t*",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fit_s",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "8117896e-ca5f-48e4-8eb3-f66d305397e1",
       "rows": [
        [
         "0",
         "Baseline lbfgs ‚Äî p=180,007",
         "0.9826588467886541",
         "0.9272835347731325",
         "0.9375033931037654",
         "0.30982714229856223",
         "354.24853587150574"
        ],
        [
         "3",
         "saga C=0.25 tol=1e-3",
         "0.8478951677055795",
         "0.46204406215766625",
         "0.8645976245269084",
         "0.0359938700122909",
         "523.0435130596161"
        ],
        [
         "1",
         "saga C=0.5 tol=1e-3 ‚Äî p=180,007",
         "0.8478940831590807",
         "0.46204406215766625",
         "0.8645976245269084",
         "0.035993036392648725",
         "453.02824425697327"
        ],
        [
         "2",
         "chi2(k=50,000) + saga C=0.5",
         "0.8478304325456321",
         "0.46181316451586724",
         "0.8645976245269084",
         "0.03605401554528541",
         "236.7608950138092"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>AP</th>\n",
       "      <th>F1@0.5</th>\n",
       "      <th>F1@t*</th>\n",
       "      <th>t*</th>\n",
       "      <th>fit_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline lbfgs ‚Äî p=180,007</td>\n",
       "      <td>0.982659</td>\n",
       "      <td>0.927284</td>\n",
       "      <td>0.937503</td>\n",
       "      <td>0.309827</td>\n",
       "      <td>354.248536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saga C=0.25 tol=1e-3</td>\n",
       "      <td>0.847895</td>\n",
       "      <td>0.462044</td>\n",
       "      <td>0.864598</td>\n",
       "      <td>0.035994</td>\n",
       "      <td>523.043513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saga C=0.5 tol=1e-3 ‚Äî p=180,007</td>\n",
       "      <td>0.847894</td>\n",
       "      <td>0.462044</td>\n",
       "      <td>0.864598</td>\n",
       "      <td>0.035993</td>\n",
       "      <td>453.028244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chi2(k=50,000) + saga C=0.5</td>\n",
       "      <td>0.847830</td>\n",
       "      <td>0.461813</td>\n",
       "      <td>0.864598</td>\n",
       "      <td>0.036054</td>\n",
       "      <td>236.760895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              desc        AP    F1@0.5     F1@t*        t*  \\\n",
       "0       Baseline lbfgs ‚Äî p=180,007  0.982659  0.927284  0.937503  0.309827   \n",
       "3             saga C=0.25 tol=1e-3  0.847895  0.462044  0.864598  0.035994   \n",
       "1  saga C=0.5 tol=1e-3 ‚Äî p=180,007  0.847894  0.462044  0.864598  0.035993   \n",
       "2      chi2(k=50,000) + saga C=0.5  0.847830  0.461813  0.864598  0.036054   \n",
       "\n",
       "        fit_s  \n",
       "0  354.248536  \n",
       "3  523.043513  \n",
       "1  453.028244  \n",
       "2  236.760895  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === √âvaluation \"optimis√©e\" sans toucher √† la baseline existante ===\n",
    "import time, numpy as np, pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, f1_score, precision_recall_curve\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "# (option) √©viter d'inonder la sortie quand on compare plusieurs runs\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "def eval_pipeline_opt(Xtr, Xte, ytr, yte, desc: str,\n",
    "                      solver=\"saga\", C=0.5, max_iter=5000, tol=1e-3, penalty=\"l2\"):\n",
    "    t0 = time.time()\n",
    "    clf = LogisticRegression(\n",
    "        solver=solver, penalty=penalty, C=C,\n",
    "        max_iter=max_iter, tol=tol,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "    clf.fit(Xtr, ytr)\n",
    "    fit_s = time.time() - t0\n",
    "\n",
    "    proba = clf.predict_proba(Xte)[:, 1]\n",
    "    ap = average_precision_score(yte, proba)\n",
    "    prec, rec, thr = precision_recall_curve(yte, proba)\n",
    "    f1 = (2*prec*rec)/(prec+rec+1e-9)\n",
    "    best_idx = int(np.nanargmax(f1))\n",
    "    thr_star = float(thr[best_idx]) if best_idx < len(thr) else 0.5\n",
    "    f1_star = float(f1[best_idx])\n",
    "    f1_05 = f1_score(yte, proba >= 0.5)\n",
    "    print(f\"[{desc}] AP={ap:.3f} | F1@0.5={f1_05:.3f} | F1@t*={f1_star:.3f} (t*={thr_star:.2f}) | fit={fit_s:.2f}s\")\n",
    "    return {\"desc\": desc, \"AP\": ap, \"F1@0.5\": f1_05, \"F1@t*\": f1_star, \"t*\": thr_star, \"fit_s\": fit_s}\n",
    "\n",
    "# On part de Xtr, Xte, ytr, yte d√©j√† construits par tes cellules pr√©c√©dentes\n",
    "compare = []\n",
    "\n",
    "# 1) Ta baseline existante (lbfgs) ‚Äî on relance la m√™me fonction que tu as d√©j√† (si dispo)\n",
    "try:\n",
    "    compare.append(eval_pipeline(Xtr, Xte, ytr, yte, desc=f\"Baseline lbfgs ‚Äî p={Xtr.shape[1]:,}\"))\n",
    "except NameError:\n",
    "    pass  # si ta fonction baseline s'appelle autrement, ignore\n",
    "\n",
    "# 2) M√™me features mais solver 'saga' mieux adapt√© aux tr√®s grandes dimensions\n",
    "compare.append(eval_pipeline_opt(Xtr, Xte, ytr, yte,\n",
    "                                desc=f\"saga C=0.5 tol=1e-3 ‚Äî p={Xtr.shape[1]:,}\",\n",
    "                                solver=\"saga\", C=0.5, max_iter=5000, tol=1e-3, penalty=\"l2\"))\n",
    "\n",
    "# 3) Variante rapide : pr√©-filtre chi¬≤ puis 'saga'\n",
    "k = min(50_000, Xtr.shape[1])\n",
    "sel = SelectKBest(chi2, k=k).fit(Xtr, ytr)\n",
    "compare.append(eval_pipeline_opt(sel.transform(Xtr), sel.transform(Xte), ytr, yte,\n",
    "                                desc=f\"chi2(k={k:,}) + saga C=0.5\", solver=\"saga\", C=0.5))\n",
    "\n",
    "# 4) (option) r√©gularisation plus forte\n",
    "compare.append(eval_pipeline_opt(Xtr, Xte, ytr, yte,\n",
    "                                desc=\"saga C=0.25 tol=1e-3\", solver=\"saga\", C=0.25, max_iter=5000, tol=1e-3))\n",
    "\n",
    "pd.DataFrame(compare).sort_values(\"AP\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf1e34a",
   "metadata": {},
   "source": [
    "üìè Comprendre les m√©triques et lire nos r√©sultats\n",
    "1) Rappels de base\n",
    "\n",
    "Pr√©cision (Precision) = TP / (TP + FP) : parmi ce que le mod√®le dit positif, quelle part est vraiment positive ?\n",
    "\n",
    "Rappel (Recall) = TP / (TP + FN) : parmi tous les vrais positifs, quelle part a √©t√© retrouv√©e ?\n",
    "\n",
    "F1-score = 2 √ó (Precision √ó Recall) / (Precision + Recall)\n",
    "‚Üí moyenne harmonique de P & R (punition si l‚Äôun des deux est bas).\n",
    "\n",
    "Ces trois m√©triques d√©pendent d‚Äôun seuil sur la probabilit√© pÃÇ(y=1).\n",
    "Changer le seuil ‚á¢ changer la matrice de confusion ‚á¢ changer Precision/Recall/F1.\n",
    "\n",
    "2) AP = Average Precision (aire sous la courbe PR)\n",
    "\n",
    "L‚ÄôAP est l‚Äôaire sous la courbe Precision‚ÄìRecall quand on fait varier le seuil de 1 ‚Üí 0.\n",
    "Elle mesure la qualit√© de classement (le mod√®le met-il ‚Äúles vrais positifs‚Äù en haut de la pile ?).\n",
    "\n",
    "Seuil-libre : pas besoin de choisir un seuil pour la comparer entre mod√®les.\n",
    "\n",
    "R√©f√©rence : l‚ÄôAP d‚Äôun classifieur al√©atoire vaut la pr√©valence de la classe positive.\n",
    "Ici, pr√©valence ‚âà 76 % ‚áí un mod√®le nul aurait AP ‚âà 0.76.\n",
    "\n",
    "Lecture de nos chiffres :\n",
    "\n",
    "lbfgs : AP = 0.983 üëâ tr√®s au-dessus de 0.76 ‚Üí excellente capacit√© √† trier les avis.\n",
    "\n",
    "saga (C=0.5) : AP = 0.848 üëâ au-dessus de 0.76 mais nettement inf√©rieur √† lbfgs ‚Üí le tri est moins bon.\n",
    "\n",
    "Pourquoi AP est cl√© ici ? Avec un dataset d√©s√©quilibr√© (76 % positifs), la courbe PR et l‚ÄôAP sont plus informatives que l‚ÄôAUC-ROC.\n",
    "\n",
    "3) F1@0.5 vs F1@t* (choix du seuil)\n",
    "\n",
    "F1@0.5 : F1 au seuil 0.5 (par d√©faut).\n",
    "Bon si les probabilit√©s sont calibr√©es (‚âà vrais risques) et si 0.5 a du sens m√©tier.\n",
    "\n",
    "F1@t* : F1 au meilleur seuil t* (celui qui maximise F1 sur l‚Äô√©chantillon √©valu√©).\n",
    "Utile pour voir le potentiel max du mod√®le, mais le choix final du seuil doit se faire sur un jeu de validation, pas sur le test.\n",
    "\n",
    "Lecture de nos chiffres :\n",
    "\n",
    "lbfgs : F1@0.5 = 0.927, F1@t* = 0.938 avec t* ‚âà 0.31\n",
    "‚Üí Tr√®s bon F1 m√™me √† 0.5. Le meilleur seuil est un peu plus bas (0.31), ce qui est coh√©rent avec un dataset √† 76 % positifs et l‚Äôeffet de class_weight='balanced' qui d√©place l‚Äôintercept.\n",
    "‚Üí Les probabilit√©s sont bien √©tal√©es (bonne calibration relative).\n",
    "\n",
    "saga (C=0.5) : F1@0.5 = 0.462, F1@t* = 0.865 avec t* ‚âà 0.04\n",
    "‚Üí √Ä 0.5, le mod√®le semble mauvais, mais si on baisse fortement le seuil, il remonte √† F1@t* = 0.865.\n",
    "‚Üí t* tr√®s faible (0.04) = les probabilit√©s sont compress√©es vers 0 ‚Üí sous-apprentissage / sur-r√©gularisation / calibration faible.\n",
    "‚Üí M√™me apr√®s optimisation du seuil, √ßa reste moins bon que lbfgs.\n",
    "\n",
    "√Ä retenir pour l‚Äôoral :\n",
    "\n",
    "AP juge le classement global (seuil-free).\n",
    "\n",
    "F1@0.5 montre la perf imm√©diate avec le seuil standard.\n",
    "\n",
    "F1@t* montre le potentiel si on optimise le seuil (√† faire sur validation, pas test).\n",
    "\n",
    "4) Interpr√©tation de t*\n",
    "\n",
    "t* ‚âà 0.31 (lbfgs) : pour maximiser F1, on classe positif d√®s ~31 % de proba.\n",
    "‚Üí logique avec une forte pr√©valence et des probas √©tal√©es.\n",
    "\n",
    "t* ‚âà 0.04 (saga) : il faut descendre tr√®s bas pour trouver les positifs ‚Üí probas sous-estim√©es, indicateur de sous-apprentissage (r√©gularisation trop forte C=0.5, tol√©rance large 1e-3, etc.).\n",
    "\n",
    "5) Temps d‚Äôentra√Ænement (fit)\n",
    "\n",
    "lbfgs : ~354 s\n",
    "\n",
    "saga C=0.5 : ~453‚Äì523 s (selon C)\n",
    "\n",
    "chi¬≤(k=50k) + saga : ~237 s\n",
    "‚Üí Le pr√©-filtre chi¬≤ divise le temps d‚Äôentra√Ænement avec la m√™me qualit√© que la variante saga C=0.5 (car m√™me solveur/r√©gularisation), mais reste loin derri√®re lbfgs en qualit√©.\n",
    "\n",
    "üß≠ D√©cision pour la suite\n",
    "\n",
    "Objectif qualit√© ‚Üí lbfgs + L2 (C=1.0) gagne nettement (AP/F1).\n",
    "Si warning de convergence : augmenter max_iter (ex. 5000) et/ou rel√¢cher tol (ex. 1e-3).\n",
    "\n",
    "Objectif vitesse ‚Üí appliquer chi¬≤(k) ou SVD(k) avant la LogReg (id√©alement avec lbfgs) pour r√©duire p et le temps, avec une faible perte attendue.\n",
    "\n",
    "Seuil de d√©cision : on choisit t sur un set de validation selon le besoin m√©tier (par ex. privil√©gier la pr√©cision pour √©viter les faux positifs, ou le rappel pour capter un max d‚Äôavis n√©gatifs).\n",
    "\n",
    "Calibration (option qualit√© produit) : mesurer le Brier score et appliquer une calibration (Platt / isotonic) si les proba sont mal √©tal√©es.\n",
    "\n",
    "TL;DR :\n",
    "lbfgs est meilleur pour ce corpus TF-IDF haute dimension (AP=0.983 ; F1@0.5=0.927).\n",
    "Les variantes saga test√©es sous-apprennent (probas √©cras√©es, t* minuscule) ; le chi¬≤ acc√©l√®re mais n‚Äô√©gale pas lbfgs en qualit√©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e818c8",
   "metadata": {},
   "source": [
    "## üíæ 8) S√©rialisation des s√©lecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ea6cc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√âcrit ‚Üí ['selector_chi2_k50000_20250912_215349.joblib', 'selector_l1_after_chi2_k50000_kept25000_20250912_215349.joblib', 'reducer_svd_k300_20250912_215349.joblib']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8) S√©rialisation des s√©lecteurs / r√©ducteurs (safe)\n",
    "from joblib import dump\n",
    "from pathlib import Path\n",
    "import time, json\n",
    "\n",
    "stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_dir = Path(\"models\"); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "written = []\n",
    "\n",
    "# Chi¬≤ (filtre)\n",
    "if 'sel' in globals():\n",
    "    p = out_dir / f\"selector_chi2_k{int(sel.k)}_{stamp}.joblib\"\n",
    "    dump({\"chi2\": sel, \"k\": int(sel.k)}, p, compress=3)\n",
    "    written.append(p.name)\n",
    "\n",
    "# L1 (m√©thode incorpor√©e apr√®s chi¬≤)\n",
    "if 'sfm' in globals():\n",
    "    kept = int(Xtr_l1.shape[1]) if 'Xtr_l1' in globals() else None\n",
    "    chi2_k = int(sel.k) if 'sel' in globals() else None\n",
    "    p = out_dir / f\"selector_l1_after_chi2_k{chi2_k}_kept{kept}_{stamp}.joblib\"\n",
    "    dump({\"l1_sfm\": sfm, \"kept\": kept, \"chi2_k\": chi2_k}, p, compress=3)\n",
    "    written.append(p.name)\n",
    "\n",
    "# SVD (r√©duction) ‚Äî seulement si tu comptes le r√©utiliser\n",
    "if 'svd_pipe' in globals():\n",
    "    k = int(getattr(svd_pipe.named_steps['truncatedsvd'], 'n_components', 0))\n",
    "    p = out_dir / f\"reducer_svd_k{k}_{stamp}.joblib\"\n",
    "    dump({\"svd_pipe\": svd_pipe, \"k\": k}, p, compress=3)\n",
    "    written.append(p.name)\n",
    "\n",
    "# Trace lisible de ce qui a √©t√© √©crit\n",
    "(meta := {\n",
    "    \"created\": stamp,\n",
    "    \"artifacts\": written,\n",
    "}).update({})\n",
    "(out_dir / f\"artifacts_{stamp}.json\").write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"√âcrit ‚Üí\", written if written else \"rien (ex√©cute d'abord les cellules chi¬≤/L1/SVD)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b7ae4f",
   "metadata": {},
   "source": [
    "## üìä 9) Tableau comparatif synth√®se ‚Äî AP / F1 / t\\* / temps\n",
    "> On rassemble baseline et variantes dans un tableau unique avec **Œî vs baseline** pour justifier le choix final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f320577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline lbfgs ‚Äî p=180,007] AP=0.985 | F1@0.5=0.932 | F1@t*=0.942 (t*=0.31) | fit=914.02s\n",
      "[saga C=0.5 tol=1e-3] AP=0.848 | F1@0.5=0.462 | F1@t*=0.865 (t*=0.04) | fit=464.46s\n",
      "[chi¬≤(k=50,000) + lbfgs] AP=0.984 | F1@0.5=0.928 | F1@t*=0.941 (t*=0.31) | fit=371.32s\n",
      "[SVD(300) + lbfgs] AP=0.849 | F1@0.5=0.504 | F1@t*=0.865 (t*=0.26) | fit=0.38s\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "desc",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "p",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "AP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ŒîAP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1@0.5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ŒîF1@0.5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1@t*",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ŒîF1@t*",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fit_s",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Œîfit_s",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0ac03354-cd6d-487c-a8c7-374e005835d0",
       "rows": [
        [
         "0",
         "Baseline lbfgs ‚Äî p=180,007",
         "180007",
         "0.9846057509533207",
         "0.0",
         "0.93239555493037",
         "0.0",
         "0.9418049367724558",
         "0.0",
         "914.0183935165405",
         "0.0"
        ],
        [
         "2",
         "chi¬≤(k=50,000) + lbfgs",
         "50000",
         "0.9837978571733197",
         "-0.0008078937800010122",
         "0.9279782319095263",
         "-0.004417323020843633",
         "0.94115100466795",
         "-0.0006539321045058166",
         "371.32141947746277",
         "-542.6969740390778"
        ],
        [
         "3",
         "SVD(300) + lbfgs",
         "300",
         "0.8493458310266152",
         "-0.1352599199267055",
         "0.5044953878488304",
         "-0.42790016708153955",
         "0.8645771727794239",
         "-0.07722776399303188",
         "0.38303422927856445",
         "-913.635359287262"
        ],
        [
         "1",
         "saga C=0.5 tol=1e-3",
         "180007",
         "0.8478952011363475",
         "-0.13671054981697317",
         "0.46204406215766625",
         "-0.4703514927727037",
         "0.8645976245269084",
         "-0.07720731224554744",
         "464.4578664302826",
         "-449.56052708625793"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>p</th>\n",
       "      <th>AP</th>\n",
       "      <th>ŒîAP</th>\n",
       "      <th>F1@0.5</th>\n",
       "      <th>ŒîF1@0.5</th>\n",
       "      <th>F1@t*</th>\n",
       "      <th>ŒîF1@t*</th>\n",
       "      <th>fit_s</th>\n",
       "      <th>Œîfit_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline lbfgs ‚Äî p=180,007</td>\n",
       "      <td>180007</td>\n",
       "      <td>0.984606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.932396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>914.018394</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chi¬≤(k=50,000) + lbfgs</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.983798</td>\n",
       "      <td>-0.000808</td>\n",
       "      <td>0.927978</td>\n",
       "      <td>-0.004417</td>\n",
       "      <td>0.941151</td>\n",
       "      <td>-0.000654</td>\n",
       "      <td>371.321419</td>\n",
       "      <td>-542.696974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVD(300) + lbfgs</td>\n",
       "      <td>300</td>\n",
       "      <td>0.849346</td>\n",
       "      <td>-0.135260</td>\n",
       "      <td>0.504495</td>\n",
       "      <td>-0.427900</td>\n",
       "      <td>0.864577</td>\n",
       "      <td>-0.077228</td>\n",
       "      <td>0.383034</td>\n",
       "      <td>-913.635359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saga C=0.5 tol=1e-3</td>\n",
       "      <td>180007</td>\n",
       "      <td>0.847895</td>\n",
       "      <td>-0.136711</td>\n",
       "      <td>0.462044</td>\n",
       "      <td>-0.470351</td>\n",
       "      <td>0.864598</td>\n",
       "      <td>-0.077207</td>\n",
       "      <td>464.457866</td>\n",
       "      <td>-449.560527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         desc       p        AP       ŒîAP    F1@0.5   ŒîF1@0.5  \\\n",
       "0  Baseline lbfgs ‚Äî p=180,007  180007  0.984606  0.000000  0.932396  0.000000   \n",
       "2      chi¬≤(k=50,000) + lbfgs   50000  0.983798 -0.000808  0.927978 -0.004417   \n",
       "3            SVD(300) + lbfgs     300  0.849346 -0.135260  0.504495 -0.427900   \n",
       "1         saga C=0.5 tol=1e-3  180007  0.847895 -0.136711  0.462044 -0.470351   \n",
       "\n",
       "      F1@t*    ŒîF1@t*       fit_s      Œîfit_s  \n",
       "0  0.941805  0.000000  914.018394    0.000000  \n",
       "2  0.941151 -0.000654  371.321419 -542.696974  \n",
       "3  0.864577 -0.077228    0.383034 -913.635359  \n",
       "1  0.864598 -0.077207  464.457866 -449.560527  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Tableau comparatif propre (baseline + variantes) ===\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def run_case(Xtr, Xte, ytr, yte, desc, solver=\"lbfgs\", C=1.0, max_iter=5000, tol=1e-3, penalty=\"l2\"):\n",
    "    out = eval_pipeline_opt(Xtr, Xte, ytr, yte, desc=desc,\n",
    "                            solver=solver, C=C, max_iter=max_iter, tol=tol, penalty=penalty)\n",
    "    out[\"p\"] = Xtr.shape[1]\n",
    "    return out\n",
    "\n",
    "compare2 = []\n",
    "\n",
    "# 0) Baseline explicite (lbfgs, sans s√©lection)\n",
    "compare2.append(run_case(Xtr, Xte, ytr, yte,\n",
    "                         desc=f\"Baseline lbfgs ‚Äî p={Xtr.shape[1]:,}\",\n",
    "                         solver=\"lbfgs\", C=1.0, max_iter=5000, tol=1e-3, penalty=\"l2\"))\n",
    "\n",
    "# 1) M√™me features, solver 'saga' (pour montrer l'effet solver)\n",
    "compare2.append(run_case(Xtr, Xte, ytr, yte,\n",
    "                         desc=\"saga C=0.5 tol=1e-3\",\n",
    "                         solver=\"saga\", C=0.5, max_iter=5000, tol=1e-3, penalty=\"l2\"))\n",
    "\n",
    "# 2) chi¬≤ + lbfgs (r√©duction p et comparaison √† armes √©gales)\n",
    "k = min(50_000, Xtr.shape[1])\n",
    "sel = SelectKBest(chi2, k=k).fit(Xtr, ytr)\n",
    "Xtr_chi, Xte_chi = sel.transform(Xtr), sel.transform(Xte)\n",
    "compare2.append(run_case(Xtr_chi, Xte_chi, ytr, yte,\n",
    "                         desc=f\"chi¬≤(k={k:,}) + lbfgs\",\n",
    "                         solver=\"lbfgs\", C=1.0, max_iter=5000, tol=1e-3, penalty=\"l2\"))\n",
    "\n",
    "# 3) (option) SVD + lbfgs (autre fa√ßon de r√©duire p)\n",
    "svd_pipe = make_pipeline(TruncatedSVD(n_components=300, random_state=42), Normalizer(copy=False))\n",
    "Xtr_svd = svd_pipe.fit_transform(Xtr, ytr); Xte_svd = svd_pipe.transform(Xte)\n",
    "compare2.append(run_case(Xtr_svd, Xte_svd, ytr, yte,\n",
    "                         desc=\"SVD(300) + lbfgs\",\n",
    "                         solver=\"lbfgs\", C=1.0, max_iter=5000, tol=1e-3, penalty=\"l2\"))\n",
    "\n",
    "# ‚Üí Tableau + deltas vs baseline\n",
    "dfc = pd.DataFrame(compare2)\n",
    "base = dfc.iloc[0].copy()\n",
    "for col in [\"AP\", \"F1@0.5\", \"F1@t*\", \"fit_s\"]:\n",
    "    dfc[f\"Œî{col}\"] = dfc[col] - base[col]\n",
    "dfc.rename(columns={\"Œîfit_s\": \"Œîfit_s\"}, inplace=True)  # alias coh√©rent\n",
    "\n",
    "dfc[[\"desc\",\"p\",\"AP\",\"ŒîAP\",\"F1@0.5\",\"ŒîF1@0.5\",\"F1@t*\",\"ŒîF1@t*\",\"fit_s\",\"Œîfit_s\"]].sort_values(\"AP\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a431e160",
   "metadata": {},
   "source": [
    "üìå Lecture des 4 variantes\n",
    "\n",
    "Baseline (TF-IDF complet ‚Üí LogReg lbfgs)\n",
    "AP=0.985 | F1@0.5=0.932 | F1@t*=0.942 (t*=0.31) | fit‚âà914s\n",
    "‚Üí Meilleure qualit√© globale. t*‚âà0.31 = proba bien √©tal√©es (calibration relative OK).\n",
    "\n",
    "SAGA (C=0.5, tol=1e-3)\n",
    "AP=0.848 | F1@0.5=0.462 | F1@t*=0.865 (t*=0.04) | fit‚âà464s\n",
    "‚Üí Forte baisse de qualit√© (AP, F1). t* minuscule ‚áí proba compress√©es vers 0 ‚áí sous-apprentissage / r√©gularisation trop forte.\n",
    "\n",
    "chi¬≤(k=50k) + lbfgs\n",
    "AP=0.984 | F1@0.5=0.928 | F1@t*=0.941 (t*=0.31) | fit‚âà371s\n",
    "‚Üí Quasi identique √† la baseline (ŒîAP ‚âà -0.001 ; ŒîF1@0.5 ‚âà -0.004), mais 2.5√ó plus rapide et beaucoup moins de variables (p=50k vs ~180k). t* inchang√© ‚áí calibration pr√©serv√©e.\n",
    "=> Excellent compromis qualit√©/vitesse.\n",
    "\n",
    "SVD(300) + lbfgs\n",
    "AP=0.849 | F1@0.5=0.504 | F1@t*=0.865 (t*=0.26) | fit‚âà0.38s\n",
    "‚Üí Ultra-rapide (‚âà 2400√ó plus vite) mais perte de qualit√© marqu√©e (ŒîAP ‚âà -0.136). √Ä r√©server si la contrainte temps est extr√™me (ex : prototypage, pr√©-tri).\n",
    "\n",
    "üéØ D√©cision pour la suite (C5.2.3)\n",
    "\n",
    "Pipeline retenu (MVP) : TF-IDF (word+char) ‚Üí chi¬≤(k=50k) ‚Üí LogReg (L2, lbfgs, C=1.0)\n",
    "Motifs : qualit√© quasi identique √† la baseline, fit 2.5√ó plus rapide, m√©moire r√©duite, calibration conserv√©e (t* ‚âà 0.31).\n",
    "\n",
    "Seuil : on choisira t sur un set de validation selon le besoin m√©tier (pr√©cision vs rappel).\n",
    "\n",
    "Pistes optionnelles : tester k=80k/100k pour voir si ŒîAP devient nul ; ou SVD(k=500‚Äì1000) si on veut explorer un compromis vitesse/qualit√© entre 300 et TF-IDF complet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71389f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.to_csv(\"tableau_comparatif_baseline_vs_variantes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf798f8b",
   "metadata": {},
   "source": [
    "¬´ Nous avons √©valu√© trois familles : filtre (chi¬≤), r√©duction (SVD) et incorpor√©e (L1).\n",
    "La m√©thode incorpor√©e s√©lectionne les variables durant l‚Äôapprentissage (L1 met des poids √† z√©ro) ‚Üí elle modifie l‚Äôespace de features et produit un masque r√©utilisable.\n",
    "L‚Äô√©valuation optimis√©e, elle, n‚Äôest pas une m√©thode de s√©lection : elle compare des configurations d‚Äôentra√Ænement (solver, r√©gularisation) sur un m√™me espace de features (ou apr√®s un filtre).\n",
    "Sur nos donn√©es, TF-IDF ‚Üí chi¬≤(k=50k) ‚Üí LogReg lbfgs offre la meilleure qualit√©/vitesse. Nous conservons L1 en d√©monstration m√©thodologique pour valider la comp√©tence ‚Äúm√©thode incorpor√©e‚Äù. ¬ª"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9be776",
   "metadata": {},
   "source": [
    "En une phrase chacune\n",
    "\n",
    "- chi¬≤ : ‚ÄúJe trie vite, ind√©pendamment du mod√®le.‚Äù\n",
    "\n",
    "- SVD : ‚ÄúJe compresse en th√®mes.‚Äù\n",
    "\n",
    "- L1 incorpor√©e : ‚ÄúJ‚Äôapprends et j‚Äô√©limine des mots pendant l‚Äôentra√Ænement.‚Äù\n",
    "\n",
    "- √âvaluation optimis√©e : ‚ÄúJe r√®gle le mod√®le sur un m√™me jeu de mots.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4f4f35",
   "metadata": {},
   "source": [
    "Pourquoi L1 est plus lente ?\n",
    "\n",
    "- Parce qu‚Äôelle entra√Æne un mod√®le entier pour d√©cider quoi couper (et en TF-IDF avec des dizaines de milliers de mots, c‚Äôest un gros jardin üòÖ).\n",
    "Chi¬≤, lui, regarde chaque mot s√©par√©ment : c‚Äôest un check binaire ultra rapide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a047d9d",
   "metadata": {},
   "source": [
    "‚ÄúOn garde TF-IDF ‚Üí chi¬≤(50k) ‚Üí LogReg lbfgs : m√™me qualit√© que la baseline, beaucoup plus rapide.\n",
    "On montre L1 en m√©thode incorpor√©e pour prouver qu‚Äôon sait s√©lectionner en apprenant, mais on ne la met pas en prod car elle est plus lente pour peu de gain ici.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c6a71",
   "metadata": {},
   "source": [
    "¬´ On utilise le SVD quand on veut compresser le TF-IDF en quelques centaines de dimensions, pour aller tr√®s vite ou travailler sur des th√®mes latents (LSA).\n",
    "C‚Äôest parfait pour explorer/visualiser ou d√©ployer l√©ger, mais on accepte une petite perte de pr√©cision.\n",
    "Dans notre cas, le meilleur compromis production est TF-IDF ‚Üí chi¬≤(50k) ‚Üí LogReg. On garde SVD pour l‚Äôexploration et les cas contraints (vitesse/m√©moire) ou pour des modules annexes (clustering, recherche s√©mantique). ¬ª"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f395c0a8",
   "metadata": {},
   "source": [
    "‚ÄúLa LogReg-L1 peut remplacer le duo s√©lection (chi¬≤) + classifieur, car elle s√©lectionne et classifie en m√™me temps. En revanche, elle ne remplace pas SVD, qui r√©alise une compression en nouvelles composantes. Pour nos donn√©es, nous retenons TF-IDF ‚Üí chi¬≤(k) ‚Üí LogReg (L2, lbfgs) pour le meilleur compromis qualit√©/temps, et nous gardons L1 comme d√©monstration de m√©thode incorpor√©e.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6a5988",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Rappel √† la comp√©tence & pourquoi c‚Äôest valid√©\n",
    "**Comp√©tence :** *C5.2.2 ‚Äî S√©lection de variables*  \n",
    "- On a impl√©ment√© **plusieurs m√©thodes** (test **chi¬≤**, **L1** embarqu√©, **SVD**, *(option RFE)*).  \n",
    "- On a **compar√©** sur un split stratifi√© avec **AP/F1** et **co√ªt** (fit), et rapport√© le **nombre de variables** retenues.  \n",
    "- On a **s√©rialis√©** les s√©lecteurs pour r√©utilisation dans l'entra√Ænement (C5.2.3) et l‚Äôinf√©rence.  \n",
    "- On a **interpr√©t√©** les features top (chi¬≤/L1) pour documenter la pertinence de la liste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b23c12f",
   "metadata": {},
   "source": [
    "√Ä quoi servent les ¬´ s√©lecteurs ¬ª (de variables) en g√©n√©ral ?\n",
    "\n",
    "But principal : choisir un sous-ensemble de features utiles et jeter le reste.\n",
    "√áa sert √† :\n",
    "\n",
    "Mieux g√©n√©raliser\n",
    "\n",
    "Moins de bruit ‚áí moins de surapprentissage ‚áí scores plus stables.\n",
    "\n",
    "Acc√©l√©rer et r√©duire la m√©moire\n",
    "\n",
    "Moins de colonnes ‚áí fit/pr√©diction plus rapides, mod√®les plus l√©gers.\n",
    "\n",
    "Am√©liorer l‚Äôinterpr√©tabilit√©\n",
    "\n",
    "On garde les signaux cl√©s ‚áí plus facile d‚Äôexpliquer pourquoi le mod√®le d√©cide.\n",
    "\n",
    "G√©rer la colin√©arit√©\n",
    "\n",
    "Features redondantes ou tr√®s corr√©l√©es ‚áí on en garde une partie.\n",
    "\n",
    "Respecter des contraintes\n",
    "\n",
    "Co√ªts d‚Äôacquisition, RGPD/PII, limites de calcul en prod, etc.\n",
    "\n",
    "Trois familles (et quand les utiliser)\n",
    "\n",
    "Filtres (ind√©pendants du mod√®le) ‚Äì ex. chi¬≤, mutual information\n",
    "\n",
    "Rapides, simples, scalables.\n",
    "\n",
    "Id√©al en pr√©-filtre quand p est √©norme (texte TF-IDF).\n",
    "\n",
    "Ne voient pas les interactions.\n",
    "\n",
    "M√©thodes incorpor√©es (embedded) ‚Äì ex. LogReg L1, arbres (importances)\n",
    "\n",
    "La s√©lection se fait pendant l‚Äôapprentissage.\n",
    "\n",
    "Plus pertinentes pour le mod√®le cibl√©, mais plus lentes.\n",
    "\n",
    "Wrappers ‚Äì ex. RFE\n",
    "\n",
    "Testent des sous-ensembles avec un mod√®le ‚Äúdans la boucle‚Äù.\n",
    "\n",
    "Pr√©cis mais co√ªteux ‚Üí plut√¥t sur sous-espaces.\n",
    "\n",
    "(Rappel : SVD/LSA n‚Äôest pas un s√©lecteur, c‚Äôest une r√©duction qui cr√©e de nouvelles composantes.)\n",
    "\n",
    "Bonnes pratiques (anti-boulettes)\n",
    "\n",
    "Toujours fitter le s√©lecteur sur le train uniquement (puis transformer le test) ‚Üí √©viter la fuite de donn√©es.\n",
    "\n",
    "Choisir k (nombre de features) par validation crois√©e ou sur un set de validation.\n",
    "\n",
    "Comparer √† une baseline sans s√©lection (montrer ŒîAP/ŒîF1/Œîtemps).\n",
    "\n",
    "Sur texte TF-IDF : commencer par chi¬≤(k), puis √©ventuellement affiner (L1) si besoin.\n",
    "\n",
    "Petite image pour retenir\n",
    "\n",
    "chi¬≤ = videur : regarde chaque feature √† l‚Äôentr√©e et dit ‚Äútu rentres / tu rentres pas‚Äù.\n",
    "\n",
    "L1 = jardinier qui taille pendant la course : le mod√®le apprend et coupe les branches inutiles.\n",
    "\n",
    "SVD = blender : compresse tous les ingr√©dients en quelques ‚Äúsaveurs‚Äù (composantes) ‚Äî ce n‚Äôest pas une s√©lection.\n",
    "\n",
    "Dans TON projet\n",
    "\n",
    "Tu utilises les s√©lecteurs pour :\n",
    "(a) garder le signal utile (meilleure g√©n√©ralisation),\n",
    "(b) r√©duire p ‚áí fit 2‚Äì3√ó plus rapide,\n",
    "(c) pr√©senter des termes cl√©s (interpr√©tation).\n",
    "\n",
    "Le compromis gagnant que tu as montr√© : TF-IDF ‚Üí chi¬≤(k=50k) ‚Üí LogReg (lbfgs) : m√™me qualit√© que la baseline, beaucoup plus rapide.\n",
    "\n",
    "L1 est gard√©e comme d√©monstration de m√©thode incorpor√©e (s√©lection pendant l‚Äôapprentissage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a40dddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be719923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
