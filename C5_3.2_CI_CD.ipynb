{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841f3c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichiers générés: serve/infer.py, serve/app.py, serve/requirements.txt, Dockerfile, tests/test_smoke.py, .github/workflows/ci.yml\n"
     ]
    }
   ],
   "source": [
    "# === C5.3.2 — Génère les fichiers d'inférence et API ===\n",
    "from pathlib import Path\n",
    "Path(\"serve\").mkdir(exist_ok=True)\n",
    "\n",
    "# -------- serve/infer.py --------\n",
    "(Path(\"serve\")/\"infer.py\").write_text(r'''\n",
    "from pathlib import Path\n",
    "import joblib, numpy as np\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "# =========================\n",
    "# SENTIMENT (TF-IDF -> LR)\n",
    "# =========================\n",
    "\n",
    "def _find_sentiment_artifact() -> Path:\n",
    "    cands = []\n",
    "    cands += sorted(Path(\"models\").glob(\"clf_logreg_chi2_gridcal_final_*.joblib\"))\n",
    "    cands += [Path(\"artifacts\")/\"sentiment_grid_best_calibrated.joblib\"]\n",
    "    cands += sorted(Path(\"models\").glob(\"clf_logreg_chi2_final_*.joblib\"))\n",
    "    cands = [p for p in cands if p.exists()]\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(\"No sentiment artifact found.\")\n",
    "    return cands[-1]\n",
    "\n",
    "def load_sentiment_bundle(path: Optional[str]=None):\n",
    "    p = Path(path) if path else _find_sentiment_artifact()\n",
    "    obj = joblib.load(p)\n",
    "    # bundle may be dict or pipeline\n",
    "    bundle = {\"path\": str(p)}\n",
    "    if isinstance(obj, dict):\n",
    "        bundle.update(obj)\n",
    "    else:\n",
    "        bundle[\"model\"] = obj\n",
    "    # Optional: load TF-IDF vectorizer if saved\n",
    "    tfidf = None\n",
    "    for cand in [\"models/tfidf_vectorizer.joblib\", \"artifacts/tfidf_vectorizer.joblib\"]:\n",
    "        q = Path(cand)\n",
    "        if q.exists():\n",
    "            tfidf = joblib.load(q)\n",
    "            break\n",
    "    bundle[\"tfidf\"] = tfidf  # may be None if your pipeline embeds it\n",
    "    return bundle\n",
    "\n",
    "def predict_sentiment_text(texts: List[str], bundle=None):\n",
    "    \"\"\"Predict from raw texts. If bundle.model is a full Pipeline it will handle vectorization.\n",
    "       Else we require a saved TF-IDF vectorizer (bundle['tfidf']).\"\"\"\n",
    "    b = bundle or load_sentiment_bundle()\n",
    "    clf = b.get(\"model_cal\") or b.get(\"model_uncal\") or b.get(\"model\")\n",
    "    if hasattr(clf, \"predict\") and hasattr(clf, \"predict_proba\") and not b.get(\"tfidf\"):\n",
    "        # assume pipeline includes vectorizer\n",
    "        y = clf.predict(texts)\n",
    "        proba = clf.predict_proba(texts)\n",
    "        return y.tolist(), proba[:,1].tolist()\n",
    "    # otherwise we need the vectorizer\n",
    "    tfidf = b.get(\"tfidf\", None)\n",
    "    if tfidf is None:\n",
    "        raise RuntimeError(\"No TF-IDF in bundle and model is not a full pipeline. Save your vectorizer as models/tfidf_vectorizer.joblib\")\n",
    "    X = tfidf.transform(texts)\n",
    "    y = clf.predict(X)\n",
    "    proba = clf.predict_proba(X)[:,1] if hasattr(clf, \"predict_proba\") else None\n",
    "    return y.tolist(), (proba.tolist() if proba is not None else None)\n",
    "\n",
    "# =========================\n",
    "# EMOTIONS (SBERT -> OVR)\n",
    "# =========================\n",
    "\n",
    "class OVRListWrapper:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    def predict_proba(self, X: np.ndarray, batch: int = 8192) -> np.ndarray:\n",
    "        n, L = X.shape[0], len(self.models)\n",
    "        out = np.empty((n, L), dtype=np.float32)\n",
    "        for i in range(0, n, batch):\n",
    "            j = min(n, i+batch)\n",
    "            Xb = np.asarray(X[i:j], dtype=np.float32)\n",
    "            for k, m in enumerate(self.models):\n",
    "                try:\n",
    "                    out[i:j, k] = m.predict_proba(Xb)[:,1]\n",
    "                except Exception:\n",
    "                    out[i:j, k] = m.decision_function(Xb)\n",
    "        return out\n",
    "\n",
    "def _find_emotions_artifact() -> Path:\n",
    "    c = []\n",
    "    c += [Path(\"artifacts\")/\"emo_grid_best_bundle.joblib\"]\n",
    "    c += sorted(Path(\"artifacts\").glob(\"emo_sgd_partial_models_resumed_final.joblib\"))\n",
    "    c += sorted(Path(\"artifacts\").glob(\"emo_sgd_partial_models_final.joblib\"))\n",
    "    c = [p for p in c if p.exists()]\n",
    "    if not c:\n",
    "        raise FileNotFoundError(\"No emotions artifact found.\")\n",
    "    return c[0]\n",
    "\n",
    "def load_emotions_runtime(path: Optional[str]=None):\n",
    "    import joblib, json\n",
    "    p = Path(path) if path else _find_emotions_artifact()\n",
    "    obj = joblib.load(p)\n",
    "    thresholds = None\n",
    "    labels = None\n",
    "    if isinstance(obj, dict):\n",
    "        est = obj.get(\"best_estimator\", obj.get(\"estimator\", None))\n",
    "        thresholds = obj.get(\"thresholds\", thresholds)\n",
    "        labels = obj.get(\"label_names_kept\", labels)\n",
    "        if est is None:\n",
    "            raise ValueError(f\"Bundle {p.name} has no best_estimator\")\n",
    "    elif isinstance(obj, list):\n",
    "        est = OVRListWrapper(obj)\n",
    "        # try thresholds file\n",
    "        from glob import glob\n",
    "        cand_thr = glob(\"artifacts/emo_thr_mean_floor*.joblib\")\n",
    "        if cand_thr:\n",
    "            thresholds = joblib.load(cand_thr[-1])\n",
    "    else:\n",
    "        est = obj\n",
    "    return est, thresholds, labels\n",
    "\n",
    "def encode_sbert(texts: List[str], model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import torch\n",
    "    dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    sbert = SentenceTransformer(model_name, device=dev)\n",
    "    X = sbert.encode(texts, batch_size=256, convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
    "    return X\n",
    "\n",
    "def predict_emotions_text(texts: List[str], runtime=None, thresholds=None, label_names=None):\n",
    "    est, thr, labels = runtime if runtime else load_emotions_runtime()\n",
    "    thr = thresholds if thresholds is not None else thr\n",
    "    labels = label_names if label_names is not None else labels\n",
    "    X = encode_sbert(texts)\n",
    "    proba = est.predict_proba(X)\n",
    "    if thr is None:\n",
    "        thr = 0.5\n",
    "    thr_arr = np.asarray(thr) if not np.isscalar(thr) else np.full(proba.shape[1], thr, dtype=float)\n",
    "    Y = (proba >= thr_arr.reshape(1,-1)).astype(int)\n",
    "    return (labels or [f\"label_{i}\" for i in range(proba.shape[1])]), Y.tolist(), proba.tolist()\n",
    "''', encoding=\"utf-8\")\n",
    "\n",
    "# -------- serve/app.py --------\n",
    "(Path(\"serve\")/\"app.py\").write_text(r'''\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from serve.infer import load_sentiment_bundle, predict_sentiment_text, load_emotions_runtime, predict_emotions_text\n",
    "\n",
    "app = FastAPI(title=\"Amazon Reviews — Sentiment & Emotions API\", version=\"1.0\")\n",
    "\n",
    "class SentimentIn(BaseModel):\n",
    "    texts: List[str]\n",
    "\n",
    "class EmotionsIn(BaseModel):\n",
    "    texts: List[str]\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"status\": \"ok\"}\n",
    "\n",
    "@app.post(\"/predict/sentiment\")\n",
    "def predict_sentiment(payload: SentimentIn):\n",
    "    bundle = load_sentiment_bundle()\n",
    "    y, proba = predict_sentiment_text(payload.texts, bundle=bundle)\n",
    "    return {\"labels\": y, \"probas\": proba}\n",
    "\n",
    "@app.post(\"/predict/emotions\")\n",
    "def predict_emotions(payload: EmotionsIn):\n",
    "    runtime = load_emotions_runtime()\n",
    "    labels, Y, proba = predict_emotions_text(payload.texts, runtime=runtime)\n",
    "    return {\"labels\": labels, \"multi_hot\": Y, \"probas\": proba}\n",
    "''', encoding=\"utf-8\")\n",
    "\n",
    "# -------- serve/requirements.txt --------\n",
    "(Path(\"serve\")/\"requirements.txt\").write_text(\"\"\"fastapi\n",
    "uvicorn\n",
    "joblib\n",
    "scikit-learn\n",
    "numpy\n",
    "pandas\n",
    "sentence-transformers\n",
    "torch\n",
    "\"\"\", encoding=\"utf-8\")\n",
    "\n",
    "# -------- Dockerfile --------\n",
    "Path(\"Dockerfile\").write_text(r'''\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# System deps (optional but useful for torch CPU wheels)\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends gcc g++ && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Copy code and artifacts\n",
    "COPY serve ./serve\n",
    "COPY artifacts ./artifacts\n",
    "COPY models ./models\n",
    "COPY docs ./docs\n",
    "\n",
    "# Install python deps\n",
    "RUN pip install --no-cache-dir -r serve/requirements.txt\n",
    "\n",
    "EXPOSE 8000\n",
    "CMD [\"uvicorn\", \"serve.app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "''', encoding=\"utf-8\")\n",
    "\n",
    "# -------- tests/test_smoke.py --------\n",
    "Path(\"tests\").mkdir(exist_ok=True, parents=True)\n",
    "Path(\"tests/test_smoke.py\").write_text(r'''\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\".\"))\n",
    "\n",
    "def test_import():\n",
    "    import serve.infer as inf\n",
    "    assert hasattr(inf, \"load_sentiment_bundle\")\n",
    "\n",
    "def test_health_like():\n",
    "    # Just ensure loaders don't crash if artifacts are present\n",
    "    import serve.infer as inf\n",
    "    try:\n",
    "        b = inf.load_sentiment_bundle()\n",
    "    except Exception:\n",
    "        b = None\n",
    "    try:\n",
    "        e = inf.load_emotions_runtime()\n",
    "    except Exception:\n",
    "        e = None\n",
    "    assert (b is not None) or (e is not None)\n",
    "''', encoding=\"utf-8\")\n",
    "\n",
    "# -------- .github/workflows/ci.yml --------\n",
    "Path(\".github\").mkdir(exist_ok=True)\n",
    "Path(\".github/workflows\").mkdir(exist_ok=True)\n",
    "Path(\".github/workflows/ci.yml\").write_text(r'''\n",
    "name: ci\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [ main, master ]\n",
    "  pull_request:\n",
    "\n",
    "jobs:\n",
    "  test-build:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      - uses: actions/setup-python@v5\n",
    "        with:\n",
    "          python-version: \"3.11\"\n",
    "      - name: Install test deps\n",
    "        run: |\n",
    "          python -m pip install --upgrade pip\n",
    "          pip install pytest\n",
    "          pip install -r serve/requirements.txt\n",
    "      - name: Run tests\n",
    "        run: pytest -q\n",
    "\n",
    "  docker:\n",
    "    if: github.ref == 'refs/heads/main'\n",
    "    needs: test-build\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      - name: Build image\n",
    "        run: docker build -t reviews-api:latest .\n",
    "      # - name: Login & Push (optional)\n",
    "      #   run: |\n",
    "      #     echo \"${{ secrets.DOCKERHUB_TOKEN }}\" | docker login -u \"${{ secrets.DOCKERHUB_USER }}\" --password-stdin\n",
    "      #     docker tag reviews-api:latest ${{ secrets.DOCKERHUB_USER }}/reviews-api:latest\n",
    "      #     docker push ${{ secrets.DOCKERHUB_USER }}/reviews-api:latest\n",
    "''', encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ Fichiers générés: serve/infer.py, serve/app.py, serve/requirements.txt, Dockerfile, tests/test_smoke.py, .github/workflows/ci.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b093c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
