# streamlit_app.py
import glob
from pathlib import Path

import numpy as np
import streamlit as st
from joblib import load
from scipy import sparse

# =========================
#   PAGE / STYLING
# =========================
st.set_page_config(page_title="Amazon Reviews â€” DÃ©mo", page_icon="ðŸ’¬", layout="wide")
st.title("ðŸ’¬ Amazon Reviews â€” DÃ©mo")

# =========================
#   SENTIMENT â€” LOADING
# =========================
@st.cache_resource
def load_sentiment_bundle():
    """
    Charge le dernier bundle entraÃ®nÃ© contenant :
      - vectorizer_word
      - vectorizer_char
      - selector_chi2  (n_in=300k -> n_out=50k)
      - model          (LogisticRegression)
      - threshold      (t*)
    """
    paths = sorted(glob.glob("models/sentiment_bundle_runtime_*.joblib"))
    if not paths:
        raise FileNotFoundError(
            "Aucun bundle 'sentiment_bundle_runtime_*.joblib' trouvÃ© dans models/.\n"
            "EntraÃ®ne-le puis relance l'appli."
        )
    bpath = paths[-1]
    b = load(bpath)
    b["_path"] = bpath
    # Sanity keys
    for key in ["vectorizer_word", "vectorizer_char", "selector_chi2", "model"]:
        if key not in b:
            raise KeyError(f"ClÃ© manquante dans le bundle: {key}")
    return b

def _stack_word_char(texts, vw, vc):
    """TF-IDF word + char -> matrice 300k colonnes (200k + 100k)."""
    Xw = vw.transform(texts)
    Xc = vc.transform(texts)
    return sparse.hstack([Xw, Xc], format="csr")

def predict_sentiment_texts(texts, bundle):
    """
    Pipeline d'infÃ©rence identique au training :
      TF-IDF(word+char) -> SelectKBest(chi2, k=50k) -> LogReg
    Renvoie: y_pred, proba, thr, debug_dict
    """
    vw = bundle["vectorizer_word"]
    vc = bundle["vectorizer_char"]
    sel = bundle["selector_chi2"]
    clf = bundle["model"]
    thr = float(bundle.get("threshold", 0.5))

    # 1) TF-IDF concat
    X = _stack_word_char(texts, vw, vc)                 # (n, 300000)
    # 2) Reduction chiÂ²
    Xr = sel.transform(X)                                # (n, 50000)
    # 3) Proba + label
    proba = clf.predict_proba(Xr)[:, 1]
    yhat = (proba >= thr).astype(int)

    dbg = {
        "bundle_path": bundle.get("_path"),
        "tfidf_shape": (X.shape[0], X.shape[1]),
        "reduced_shape": (Xr.shape[0], Xr.shape[1]),
        "lr_coef_shape": getattr(getattr(clf, "coef_", None), "shape", None),
        "threshold": thr,
    }
    return yhat, proba, thr, dbg

# =========================
#   EMOTIONS â€” (OPTIONNEL)
# =========================
@st.cache_resource
def load_emotions_runtime():
    """
    Optionnel : si tu as un runtime Ã©motions, charge-le ici et
    renvoie un callable `predict(texts, topk, thr)` qui renvoie
    (labels, topk_indices, topk_scores, binarized_per_text).

    Si rien n'est dispo, on renvoie None.
    """
    try:
        # Exemple : si tu as dÃ©jÃ  un module interne de service
        # from serve.infer import load_emotions_runtime as _load
        # return _load()
        return None
    except Exception:
        return None

# =========================
#   UI
# =========================
placeholder = "Great battery life but the screen is dim.\nTerrible packaging, but excellent sound."
txt = st.text_area("Collez un ou plusieurs avis (1 par ligne) :", placeholder, height=180)

cols = st.columns([1, 1])
with cols[0]:
    st.subheader("Sentiment")
with cols[1]:
    st.subheader("Ã‰motions")
    thr_override = st.slider("Seuil global (override)", 0.0, 0.9, 0.30, 0.01, help="Seuil affichage Ã©motions (optionnel)")
    topk = st.selectbox("Top-k Ã  afficher", [1, 2, 3, 5, 10], index=2)
    always_show = st.checkbox("Toujours afficher Top-k (mÃªme si aucune nâ€™atteint le seuil)", value=True)

analyze = st.button("Analyser")

if analyze and txt.strip():
    texts = [t.strip() for t in txt.splitlines() if t.strip()]

    # ---------- SENTIMENT ----------
    with cols[0]:
        try:
            sb = load_sentiment_bundle()
            yhat, proba, thr, dbg = predict_sentiment_texts(texts, sb)
            for t, p, y in zip(texts, proba, yhat):
                lbl = "Positif" if y == 1 else "NÃ©gatif"
                st.write(f"- **{t[:80]}â€¦** â†’ {lbl}  (p={float(p):.3f}, thr={thr:.2f})")
        except Exception as e:
            st.error(f"Erreur sentiment : {e}")

    # ---------- EMOTIONS (OPTIONNEL) ----------
    with cols[1]:
        runtime = load_emotions_runtime()
        if runtime is None:
            st.info("ModÃ¨le Ã©motions non trouvÃ© (optionnel). Ajoute ton runtime plus tard.")
        else:
            try:
                # Exemple dâ€™API attendue si tu branches ton runtime :
                # labels, top_idx, top_scores, binarized = runtime(texts, topk=topk, thr=thr_override)
                # for i, t in enumerate(texts):
                #     if always_show:
                #         tops = [f"{labels[j]} ({top_scores[i][k]:.2f})" for k, j in enumerate(top_idx[i])]
                #         st.write(f"- **{t[:80]}â€¦** â†’ " + (", ".join(tops) if tops else "aucune"))
                #     else:
                #         active = [labels[j] for j, v in enumerate(binarized[i]) if v == 1]
                #         st.write(f"- **{t[:80]}â€¦** â†’ " + (", ".join(active) if active else "aucune"))
                st.info("Brancher ici lâ€™infÃ©rence Ã©motions quand ton runtime sera prÃªt.")
            except Exception as e:
                st.error(f"Erreur Ã©motions : {e}")

    # ---------- DEBUG ----------
    with st.expander("ðŸ”§ Infos chargement / Debug"):
        try:
            st.json(dbg)
        except Exception:
            st.write("Aucune info debug.")
